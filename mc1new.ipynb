{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "Tiny ImageNet contains 100000 images of 200 classes (500 for each class) downsized to 64Ã—64 colored images. Each class has 500 training images, 50 validation images and 50 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "For the evaluation of the model, we will use accuracy as our metric. It is straightforward and defined as follows:\n",
    "$$ \\text{Accuracy} = \\frac{\\text{correct classifications}}{\\text{all classifications}} $$\n",
    "\n",
    "However, accuracy has a disadvantage for multiclass classification problems, as it does not consider class imbalances. If our model is biased towards one class, and that class has the highest occurrence, accuracy may fail to reflect this bias. In our case, since the dataset does not have class imbalances, accuracy should be sufficient for our evaluation.\n",
    "\n",
    "To estimate the error in the chosen metric, we could also consider using an alternative metric like the F1 Score, which penalizes false predictions rather than just summarizing the correct ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Architecture\n",
    "- Explain base model\n",
    "- Train with single sample or batch and show that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_classes: int,\n",
    "        confs: List[Tuple[str, Dict]],\n",
    "        in_channels: int,\n",
    "        weight_init=None,\n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.net = nn.ModuleList()\n",
    "\n",
    "        linear_idxs = [idx for idx, (layer, _) in enumerate(confs) if layer == \"L\"]\n",
    "        linear_start = linear_idxs[0]\n",
    "        convolution_conf = confs[:linear_start]\n",
    "        linear_conf = confs[linear_start:]\n",
    "        for layer, conf in convolution_conf:\n",
    "            if layer == \"C\":\n",
    "                self.net.append(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels,\n",
    "                        out_channels=conf[\"channels\"],\n",
    "                        kernel_size=conf[\"kernel\"],\n",
    "                        stride=conf.get(\"stride\", 1),\n",
    "                        padding=conf.get(\"padding\", 0),\n",
    "                    )\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"batch_norm\", False):\n",
    "                    self.net.append(nn.BatchNorm2d(conf[\"channels\"]))\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "                in_channels = conf[\"channels\"]\n",
    "            elif layer == \"P\":\n",
    "                self.net.append(nn.MaxPool2d(kernel_size=conf[\"kernel\"]))\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Layer {layer} not implemented\")\n",
    "\n",
    "        self.dim = utils.get_dim_after_conv_and_pool(dim_init=dim, confs=confs)\n",
    "        print(f\"self.dim: {self.dim},\\nin_channels: {in_channels}\")\n",
    "        for idx, (layer, conf) in enumerate(linear_conf):\n",
    "            if idx == 0:\n",
    "                self.net.append(nn.Flatten())\n",
    "                self.net.append(\n",
    "                    nn.Linear(self.dim * self.dim * in_channels, conf[\"units\"])\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "            elif idx == len(linear_conf) - 1:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], num_classes))\n",
    "            else:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], conf[\"units\"]))\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, H, W, C = x.shape\n",
    "        x = x.permute(\n",
    "            0, 3, 1, 2\n",
    "        )  # Adjust (batch_size, H, W, C) to (batch_size, C, H, W)\n",
    "        assert x.shape == (N, C, H, W)\n",
    "\n",
    "        for layer in self.net:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = [\n",
    "    (\"C\", {\"kernel\": 3, \"channels\": 16}),\n",
    "    (\"P\", {\"kernel\": 2}),\n",
    "    (\"C\", {\"kernel\": 3, \"channels\": 32}),\n",
    "    (\"P\", {\"kernel\": 2}),\n",
    "    (\"L\", {\"units\": 500, \"dropout\": 0.5}),\n",
    "    (\"L\", {\"units\": 500, \"dropout\": 0.5}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.dim: 14,\n",
      "in_channels: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1232,  0.0999,  0.0368,  ...,  0.0669,  0.0408,  0.0596],\n",
       "        [ 0.0231,  0.0232, -0.0239,  ...,  0.0165,  0.0469,  0.1135],\n",
       "        [-0.0378,  0.0657,  0.0646,  ...,  0.0202, -0.0382, -0.0960],\n",
       "        ...,\n",
       "        [ 0.0591, -0.0282,  0.0562,  ...,  0.0490, -0.0234, -0.0127],\n",
       "        [ 0.0834,  0.1145,  0.0871,  ...,  0.0984, -0.0463,  0.0839],\n",
       "        [ 0.0103,  0.0018,  0.0955,  ..., -0.0178, -0.0084,  0.0198]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(10, 64, 64, 3)\n",
    "model = CNN(dim=64, num_classes=200, confs=confs, in_channels=3)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD, Tuning of Learning Rate and Batch Size\n",
    "- Explain SGD\n",
    "- Explain Learning Rate\n",
    "- Explain Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD, Weight Initialization, Model Complexity, Convolution Settings\n",
    "- Explain what you will do here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization\n",
    "- Explain the different weight initialization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Complexity\n",
    "- Explain what you will do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variant 1\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variant 2\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variant 3\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variant 4\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "- Variant 1\n",
    "- Variant 2\n",
    "- Variant 3\n",
    "- Variant 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "- Briefly describe what the goal of regularization methods in general is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1/L2\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "- To what extent is this goal achieved in the given case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batchnorm (without REG, with SGD)\n",
    "- Evaluate whether Batchnorm is useful. Describe what the idea of BN is, what it is supposed to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without BN, without REG\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without BN, with REG\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
