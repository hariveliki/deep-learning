{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "Tiny ImageNet contains 100000 images of 200 classes (500 for each class) downsized to 64Ã—64 colored images. Each class has 500 training images, 50 validation images and 50 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "For the evaluation of the model, we will use accuracy as our metric. It is straightforward and defined as follows:\n",
    "$$ \\text{Accuracy} = \\frac{\\text{correct classifications}}{\\text{all classifications}} $$\n",
    "\n",
    "However, accuracy has a disadvantage for multiclass classification problems, as it does not consider class imbalances. If our model is biased towards one class, and that class has the highest occurrence, accuracy may fail to reflect this bias. In our case, since the dataset does not have class imbalances, accuracy should be sufficient for our evaluation.\n",
    "\n",
    "To estimate the error in the chosen metric, we could also consider using an alternative metric like the F1 Score, which penalizes false predictions rather than just summarizing the correct ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Architecture\n",
    "- The base model consists of two convolutional layers for feature extraction and two pooling layers to reduce the spatial dimension of the image. Two fully connected layer ensure enough parameters. The goal is to train with a single sample or batch and to show that it works as well as in the next step to find a proper learning rate and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hariveliki/miniconda3/envs/eml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import utils\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_classes: int,\n",
    "        confs: List[Tuple[str, Dict]],\n",
    "        in_channels: int,\n",
    "        weight_init=None,\n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.net = nn.ModuleList()\n",
    "\n",
    "        linear_idxs = [idx for idx, (layer, _) in enumerate(confs) if layer == \"L\"]\n",
    "        linear_start = linear_idxs[0]\n",
    "        convolution_conf = confs[:linear_start]\n",
    "        linear_conf = confs[linear_start:]\n",
    "        for layer, conf in convolution_conf:\n",
    "            if layer == \"C\":\n",
    "                self.net.append(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels,\n",
    "                        out_channels=conf[\"channels\"],\n",
    "                        kernel_size=conf[\"kernel\"],\n",
    "                        stride=conf.get(\"stride\", 1),\n",
    "                        padding=conf.get(\"padding\", 0),\n",
    "                    )\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"batch_norm\", False):\n",
    "                    self.net.append(nn.BatchNorm2d(conf[\"channels\"]))\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "                in_channels = conf[\"channels\"]\n",
    "            elif layer == \"P\":\n",
    "                self.net.append(nn.MaxPool2d(kernel_size=conf[\"kernel\"]))\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Layer {layer} not implemented\")\n",
    "\n",
    "        self.dim = utils.get_dim_after_conv_and_pool(dim_init=dim, confs=confs)\n",
    "        for idx, (layer, conf) in enumerate(linear_conf):\n",
    "            if idx == 0:\n",
    "                self.net.append(nn.Flatten())\n",
    "                self.net.append(\n",
    "                    nn.Linear(self.dim * self.dim * in_channels, conf[\"units\"])\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "            elif idx == len(linear_conf) - 1:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], num_classes))\n",
    "            else:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], conf[\"units\"]))\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, H, W, C = x.shape\n",
    "        x = x.permute(\n",
    "            0, 3, 1, 2\n",
    "        )  # Adjust (batch_size, H, W, C) to (batch_size, C, H, W)\n",
    "        assert x.shape == (N, C, H, W)\n",
    "\n",
    "        for layer in self.net:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = [\n",
    "    (\"C\", {\"kernel\": 3, \"channels\": 16}),\n",
    "    (\"P\", {\"kernel\": 2}),\n",
    "    (\"C\", {\"kernel\": 3, \"channels\": 32}),\n",
    "    (\"P\", {\"kernel\": 2}),\n",
    "    (\"L\", {\"units\": 500}),\n",
    "    (\"L\", {\"units\": 500}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 62, 62]             448\n",
      "              ReLU-2           [-1, 16, 62, 62]               0\n",
      "         MaxPool2d-3           [-1, 16, 31, 31]               0\n",
      "            Conv2d-4           [-1, 32, 29, 29]           4,640\n",
      "              ReLU-5           [-1, 32, 29, 29]               0\n",
      "         MaxPool2d-6           [-1, 32, 14, 14]               0\n",
      "           Flatten-7                 [-1, 6272]               0\n",
      "            Linear-8                  [-1, 500]       3,136,500\n",
      "              ReLU-9                  [-1, 500]               0\n",
      "           Linear-10                  [-1, 200]         100,200\n",
      "================================================================\n",
      "Total params: 3,241,788\n",
      "Trainable params: 3,241,788\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1.57\n",
      "Params size (MB): 12.37\n",
      "Estimated Total Size (MB): 13.98\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(10, 64, 64, 3)\n",
    "model = CNN(dim=64, num_classes=200, confs=confs, in_channels=3)\n",
    "model(x)\n",
    "summary(model, (64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x10605e470> <torch.utils.data.dataloader.DataLoader object at 0x10605c760>\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = utils.get_data(batch_size=None)\n",
    "print(train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD, Tuning of Learning Rate and Batch Size\n",
    "- Explain SGD\n",
    "- Explain Learning Rate\n",
    "- Explain Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD, Weight Initialization, Model Complexity, Convolution Settings\n",
    "- Explain what you will do here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization\n",
    "- Explain the different weight initialization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Complexity\n",
    "- Explain what you will do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variant 1\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_classes: int,\n",
    "        confs: List[Tuple[str, Dict]],\n",
    "        in_channels: int,\n",
    "        weight_init=None,\n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.net = nn.ModuleList()\n",
    "\n",
    "        linear_idxs = [idx for idx, (layer, _) in enumerate(confs) if layer == \"L\"]\n",
    "        linear_start = linear_idxs[0]\n",
    "        convolution_conf = confs[:linear_start]\n",
    "        linear_conf = confs[linear_start:]\n",
    "        for layer, conf in convolution_conf:\n",
    "            if layer == \"C\":\n",
    "                self.net.append(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels,\n",
    "                        out_channels=conf[\"channels\"],\n",
    "                        kernel_size=conf[\"kernel\"],\n",
    "                        stride=conf.get(\"stride\", 1),\n",
    "                        padding=conf.get(\"padding\", 0),\n",
    "                    )\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"batch_norm\", False):\n",
    "                    self.net.append(nn.BatchNorm2d(conf[\"channels\"]))\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "                in_channels = conf[\"channels\"]\n",
    "            elif layer == \"P\":\n",
    "                self.net.append(nn.MaxPool2d(kernel_size=conf[\"kernel\"]))\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Layer {layer} not implemented\")\n",
    "\n",
    "        self.dim = utils.get_dim_after_conv_and_pool(dim_init=dim, confs=confs)\n",
    "        print(f\"self.dim: {self.dim},\\nin_channels: {in_channels}\")\n",
    "        for idx, (layer, conf) in enumerate(linear_conf):\n",
    "            if idx == 0:\n",
    "                self.net.append(nn.Flatten())\n",
    "                self.net.append(\n",
    "                    nn.Linear(self.dim * self.dim * in_channels, conf[\"units\"])\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "            elif idx == len(linear_conf) - 1:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], num_classes))\n",
    "            else:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], conf[\"units\"]))\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, H, W, C = x.shape\n",
    "        x = x.permute(\n",
    "            0, 3, 1, 2\n",
    "        )  # Adjust (batch_size, H, W, C) to (batch_size, C, H, W)\n",
    "        assert x.shape == (N, C, H, W)\n",
    "\n",
    "        for layer in self.net:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variant 2\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_classes: int,\n",
    "        confs: List[Tuple[str, Dict]],\n",
    "        in_channels: int,\n",
    "        weight_init=None,\n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.net = nn.ModuleList()\n",
    "\n",
    "        linear_idxs = [idx for idx, (layer, _) in enumerate(confs) if layer == \"L\"]\n",
    "        linear_start = linear_idxs[0]\n",
    "        convolution_conf = confs[:linear_start]\n",
    "        linear_conf = confs[linear_start:]\n",
    "        for layer, conf in convolution_conf:\n",
    "            if layer == \"C\":\n",
    "                self.net.append(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels,\n",
    "                        out_channels=conf[\"channels\"],\n",
    "                        kernel_size=conf[\"kernel\"],\n",
    "                        stride=conf.get(\"stride\", 1),\n",
    "                        padding=conf.get(\"padding\", 0),\n",
    "                    )\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"batch_norm\", False):\n",
    "                    self.net.append(nn.BatchNorm2d(conf[\"channels\"]))\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "                in_channels = conf[\"channels\"]\n",
    "            elif layer == \"P\":\n",
    "                self.net.append(nn.MaxPool2d(kernel_size=conf[\"kernel\"]))\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Layer {layer} not implemented\")\n",
    "\n",
    "        self.dim = utils.get_dim_after_conv_and_pool(dim_init=dim, confs=confs)\n",
    "        print(f\"self.dim: {self.dim},\\nin_channels: {in_channels}\")\n",
    "        for idx, (layer, conf) in enumerate(linear_conf):\n",
    "            if idx == 0:\n",
    "                self.net.append(nn.Flatten())\n",
    "                self.net.append(\n",
    "                    nn.Linear(self.dim * self.dim * in_channels, conf[\"units\"])\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "            elif idx == len(linear_conf) - 1:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], num_classes))\n",
    "            else:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], conf[\"units\"]))\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, H, W, C = x.shape\n",
    "        x = x.permute(\n",
    "            0, 3, 1, 2\n",
    "        )  # Adjust (batch_size, H, W, C) to (batch_size, C, H, W)\n",
    "        assert x.shape == (N, C, H, W)\n",
    "\n",
    "        for layer in self.net:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variant 3\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_classes: int,\n",
    "        confs: List[Tuple[str, Dict]],\n",
    "        in_channels: int,\n",
    "        weight_init=None,\n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.net = nn.ModuleList()\n",
    "\n",
    "        linear_idxs = [idx for idx, (layer, _) in enumerate(confs) if layer == \"L\"]\n",
    "        linear_start = linear_idxs[0]\n",
    "        convolution_conf = confs[:linear_start]\n",
    "        linear_conf = confs[linear_start:]\n",
    "        for layer, conf in convolution_conf:\n",
    "            if layer == \"C\":\n",
    "                self.net.append(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels,\n",
    "                        out_channels=conf[\"channels\"],\n",
    "                        kernel_size=conf[\"kernel\"],\n",
    "                        stride=conf.get(\"stride\", 1),\n",
    "                        padding=conf.get(\"padding\", 0),\n",
    "                    )\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"batch_norm\", False):\n",
    "                    self.net.append(nn.BatchNorm2d(conf[\"channels\"]))\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "                in_channels = conf[\"channels\"]\n",
    "            elif layer == \"P\":\n",
    "                self.net.append(nn.MaxPool2d(kernel_size=conf[\"kernel\"]))\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Layer {layer} not implemented\")\n",
    "\n",
    "        self.dim = utils.get_dim_after_conv_and_pool(dim_init=dim, confs=confs)\n",
    "        print(f\"self.dim: {self.dim},\\nin_channels: {in_channels}\")\n",
    "        for idx, (layer, conf) in enumerate(linear_conf):\n",
    "            if idx == 0:\n",
    "                self.net.append(nn.Flatten())\n",
    "                self.net.append(\n",
    "                    nn.Linear(self.dim * self.dim * in_channels, conf[\"units\"])\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "            elif idx == len(linear_conf) - 1:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], num_classes))\n",
    "            else:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], conf[\"units\"]))\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, H, W, C = x.shape\n",
    "        x = x.permute(\n",
    "            0, 3, 1, 2\n",
    "        )  # Adjust (batch_size, H, W, C) to (batch_size, C, H, W)\n",
    "        assert x.shape == (N, C, H, W)\n",
    "\n",
    "        for layer in self.net:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variant 4\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_classes: int,\n",
    "        confs: List[Tuple[str, Dict]],\n",
    "        in_channels: int,\n",
    "        weight_init=None,\n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.net = nn.ModuleList()\n",
    "\n",
    "        linear_idxs = [idx for idx, (layer, _) in enumerate(confs) if layer == \"L\"]\n",
    "        linear_start = linear_idxs[0]\n",
    "        convolution_conf = confs[:linear_start]\n",
    "        linear_conf = confs[linear_start:]\n",
    "        for layer, conf in convolution_conf:\n",
    "            if layer == \"C\":\n",
    "                self.net.append(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels,\n",
    "                        out_channels=conf[\"channels\"],\n",
    "                        kernel_size=conf[\"kernel\"],\n",
    "                        stride=conf.get(\"stride\", 1),\n",
    "                        padding=conf.get(\"padding\", 0),\n",
    "                    )\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"batch_norm\", False):\n",
    "                    self.net.append(nn.BatchNorm2d(conf[\"channels\"]))\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "                in_channels = conf[\"channels\"]\n",
    "            elif layer == \"P\":\n",
    "                self.net.append(nn.MaxPool2d(kernel_size=conf[\"kernel\"]))\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Layer {layer} not implemented\")\n",
    "\n",
    "        self.dim = utils.get_dim_after_conv_and_pool(dim_init=dim, confs=confs)\n",
    "        print(f\"self.dim: {self.dim},\\nin_channels: {in_channels}\")\n",
    "        for idx, (layer, conf) in enumerate(linear_conf):\n",
    "            if idx == 0:\n",
    "                self.net.append(nn.Flatten())\n",
    "                self.net.append(\n",
    "                    nn.Linear(self.dim * self.dim * in_channels, conf[\"units\"])\n",
    "                )\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "            elif idx == len(linear_conf) - 1:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], num_classes))\n",
    "            else:\n",
    "                self.net.append(nn.Linear(conf[\"units\"], conf[\"units\"]))\n",
    "                self.net.append(nn.ReLU())\n",
    "                if conf.get(\"dropout\", 0):\n",
    "                    self.net.append(nn.Dropout(conf[\"dropout\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, H, W, C = x.shape\n",
    "        x = x.permute(\n",
    "            0, 3, 1, 2\n",
    "        )  # Adjust (batch_size, H, W, C) to (batch_size, C, H, W)\n",
    "        assert x.shape == (N, C, H, W)\n",
    "\n",
    "        for layer in self.net:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "- Variant 1\n",
    "- Variant 2\n",
    "- Variant 3\n",
    "- Variant 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "- Briefly describe what the goal of regularization methods in general is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1/L2\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "- To what extent is this goal achieved in the given case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batchnorm (without REG, with SGD)\n",
    "- Evaluate whether Batchnorm is useful. Describe what the idea of BN is, what it is supposed to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without BN, without REG\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without BN, with REG\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "- Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
